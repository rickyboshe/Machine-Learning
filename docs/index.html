<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Spam Filter</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Machine Learning</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Spam Filter</a>
</li>
<li>
  <a href="Mental.html">Mental Health</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Spam Filter</h1>

</div>


<br></br>
<center>
<div id="sms-spam-filter-sorting-spam-messages" class="section level1">
<h1>SMS Spam Filter: Sorting Spam Messages</h1>
</center>
<p>This project looks at utilizing Naive Bayes algorithm to create a spam filter. Th algorithm will be trained, tested and validated on a dataset of 5,574 SMS messages that have already been classified. The dataset was compiled by by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the <a href="https://archive.ics.uci.edu/ml/datasets/sms+spam+collection">The UCI Machine Learning Repository</a></p>
<p>The DataExloper package is a powerful R package that allows quick and simplified data exploration. helps identify types of data, any missing values etc.</p>
<pre class="r"><code>glimpse(spam)</code></pre>
<pre><code>## Rows: 4,837
## Columns: 2
## $ label &lt;chr&gt; &quot;ham&quot;, &quot;ham&quot;, &quot;spam&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;spam&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;sp...
## $ sms   &lt;chr&gt; &quot;Go until jurong point, crazy.. Available only in bugis n gre...</code></pre>
<pre class="r"><code>#Utilizing the data explorer package 
plot_intro(spam, ggtheme = theme_bw())</code></pre>
<p><img src="index_files/figure-html/data-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot_bar(spam, ggtheme = theme_bw())</code></pre>
<pre><code>## 1 columns ignored with more than 50 categories.
## sms: 4512 categories</code></pre>
<p><img src="index_files/figure-html/data-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary&lt;-spam%&gt;%
  group_by(label)%&gt;%
  summarize(freq=n())%&gt;%
  mutate(per=freq/nrow(spam))</code></pre>
<p>Just over 86% (4,199) of the SMS are non-spam while the rest are spam messages. There are no missing values making the next data analysis steps easier.</p>
<p>Our spam filter will utilize a machine learning process to maximize the predictive ability of the algorithm. For a succesful machine learning process, we need to split our data into 3 parts: 1. <strong>Training set:</strong> which is used to “train” the computer how to classify messages. 2. <strong>Cross-validation set:</strong> which is used to assess how different choices of <em>alpha</em> will affect the prediction accuracy. 3. <strong>Test set:</strong> which is used to test how good the spam filter is with classifying new messages.</p>
<p>A rule of thumb is usually 80-10-10 split. This ensures as much training data for the algorithm to learn as possible. A good training set will help develop all of the conditional probabilities and vocabulary.</p>
<pre class="r"><code>set.seed(1)

# Calculate some helper values to split the dataset
n &lt;- nrow(spam)
n_training &lt;- 0.8 * n
n_cv &lt;- 0.1 * n
n_test &lt;- 0.1 * n

# Create the random indices for training set
train_indices &lt;- sample(1:n, size = n_training, replace = FALSE)

# Get indices not used by the training set
remaining_indices &lt;- setdiff(1:n, train_indices)

# Remaining indices are already randomized, just allocate correctly
cv_indices &lt;- remaining_indices[1:(length(remaining_indices)/2)]
test_indices &lt;- remaining_indices[((length(remaining_indices)/2) + 1):length(remaining_indices)]

# Use the indices to create each of the datasets
spam_train &lt;- spam[train_indices,]
spam_cv &lt;- spam[cv_indices,]
spam_test &lt;- spam[test_indices,]

# Sanity check: are the ratios of ham to spam relatively constant?
print(mean(spam_train$label == &quot;ham&quot;))</code></pre>
<pre><code>## [1] 0.8658568</code></pre>
<pre class="r"><code>print(mean(spam_cv$label == &quot;ham&quot;))</code></pre>
<pre><code>## [1] 0.8719008</code></pre>
<pre class="r"><code>print(mean(spam_test$label == &quot;ham&quot;))</code></pre>
<pre><code>## [1] 0.8822314</code></pre>
<p>The means of each dataset shows that the number of non-spam messages in the training, cross-validation and testing datasets are relatively close to each other. The next step is to use the training set to teach the algorithm to classify new messages</p>
<pre class="r"><code>#Lower case all the messages, remove punctuation and unicode
tidy_train &lt;- spam_train %&gt;% 
  mutate(sms = str_to_lower(sms) %&gt;% 
           str_squish %&gt;% #remove whitespace 
           str_replace_all(&quot;[[:punct:]]&quot;, &quot;&quot;) %&gt;%
           str_replace_all(&quot;[\u0094\u0092\u0096\n\t]&quot;, &quot;&quot;) %&gt;% #Unicode characters
           str_replace_all(&quot;[[:digit:]]&quot;, &quot;&quot;))

# Creating the vocabulary
vocabulary &lt;- NULL
messages &lt;- tidy_train %&gt;%
  pull(sms)

# Iterate through the messages and add to the vocabulary
for (m in messages) {
  words &lt;- str_split(m, &quot; &quot;)[[1]]
  vocabulary &lt;- c(vocabulary, words)
}

# Remove duplicates from the vocabulary 
vocabulary &lt;- vocabulary %&gt;% 
  unique()</code></pre>
<p>After building the vocabulary, we then go to isolate spam texts from non spam text from the training data and then idolating the vocabularies found in each set of texts.</p>
<pre class="r"><code># Isolate the spam and ham messages
spam_messages &lt;- tidy_train %&gt;% 
  filter(label == &quot;spam&quot;) %&gt;% 
  pull(sms)
ham_messages &lt;- tidy_train %&gt;% 
  filter(label == &quot;ham&quot;) %&gt;% 
  pull(sms)

# Isolate the vocabulary in spam and ham messages
spam_vocab &lt;- NULL
for (sm in spam_messages) {
  words &lt;- str_split(sm, &quot; &quot;)[[1]]
  spam_vocab  &lt;- c(spam_vocab, words)
}
spam_vocab &lt;- spam_vocab %&gt;% unique
ham_vocab &lt;- NULL
for (hm in ham_messages) {
  words &lt;- str_split(hm, &quot; &quot;)[[1]]
  ham_vocab &lt;- c(ham_vocab, words)
}
ham_vocab &lt;- ham_vocab %&gt;% unique()

# Length of the vocabulary sets 
n_spam &lt;- spam_vocab %&gt;% length()
n_ham &lt;- ham_vocab %&gt;% length()
n_vocabulary &lt;- vocabulary %&gt;% length()</code></pre>
<pre class="r"><code># Marginal probability of a training message being spam or ham
p_spam &lt;- mean(tidy_train$label == &quot;spam&quot;)
p_ham &lt;- mean(tidy_train$label == &quot;ham&quot;)

# Break up the spam and ham counting into their own tibbles
spam_counts &lt;- tibble(
  word = spam_vocab
) %&gt;% 
  mutate(
    # Calculate the number of times a word appears in spam
    spam_count = map_int(word, function(w) {
      
      # Count how many times each word appears in all spam messsages, then sum
      map_int(spam_messages, function(sm) {
        (str_split(sm, &quot; &quot;)[[1]] == w) %&gt;% sum # for a single message
      }) %&gt;% 
        sum # then summing over all messages
    })
  )

# Non-spam 
ham_counts &lt;- tibble(
  word = ham_vocab
) %&gt;% 
  mutate(
    # Calculate the number of times a word appears in ham
    ham_count = map_int(word, function(w) {
      
      # Count how many times each word appears in all ham messsages, then sum
      map_int(ham_messages, function(hm) {
        (str_split(hm, &quot; &quot;)[[1]] == w) %&gt;% sum 
      }) %&gt;% 
        sum
      
    })
  )

# Join tibbles
word_counts &lt;- full_join(spam_counts, ham_counts, by = &quot;word&quot;) %&gt;% 
  mutate(spam_count = ifelse(is.na(spam_count), 0, spam_count),
         ham_count = ifelse(is.na(ham_count), 0, ham_count))</code></pre>
<p>As we have our spam and non-spam probabilities trained on the training data and vocabulary, we can go ahead and classify new messages.</p>
<pre class="r"><code># Create a function that makes it easy to classify a tibble of messages
# we add an alpha argument to make it easy to recalculate probabilities based on this alpha (default to 1)
classify &lt;- function(message, alpha = 1) {
  
  # Splitting and cleaning the new message (same cleaning procedure used on the training messages)
  clean_message &lt;- str_to_lower(message) %&gt;% 
    str_squish %&gt;% 
      str_replace_all(&quot;[[:punct:]]&quot;, &quot;&quot;) %&gt;% 
      str_replace_all(&quot;[\u0094\u0092\u0096\n\t]&quot;, &quot;&quot;) %&gt;% # Unicode characters
      str_replace_all(&quot;[[:digit:]]&quot;, &quot;&quot;)
  
  words &lt;- str_split(clean_message, &quot; &quot;)[[1]]

  # Find the words that new (non-existent in the training vocabulary)
  new_words &lt;- setdiff(vocabulary, words)
  
  # Add them to the word_counts 
  new_word_probs &lt;- tibble(
    word = new_words,
    spam_prob = 1,
    ham_prob = 1
  )
  # Filter down the probabilities to the words present 
  present_probs &lt;- word_counts %&gt;% 
    filter(word %in% words) %&gt;% 
    mutate(spam_prob = (spam_count + alpha) / (n_spam + alpha * n_vocabulary),
           ham_prob = (ham_count + alpha) / (n_ham + alpha * n_vocabulary)) %&gt;% 
    bind_rows(new_word_probs) %&gt;% 
    pivot_longer(
      cols = c(&quot;spam_prob&quot;, &quot;ham_prob&quot;),
      names_to = &quot;label&quot;,
      values_to = &quot;prob&quot;) %&gt;% 
    group_by(label) %&gt;% 
    summarize(wi_prob = prod(prob))
 
  # Calculate the conditional probabilities
  p_spam_given_message &lt;- p_spam * (present_probs %&gt;% filter(label == &quot;spam_prob&quot;) %&gt;% pull(wi_prob))
  p_ham_given_message &lt;- p_ham * (present_probs %&gt;% filter(label == &quot;ham_prob&quot;) %&gt;% pull(wi_prob))
  
  # Classify the message based on the probability
  ifelse(p_spam_given_message &gt;= p_ham_given_message, &quot;spam&quot;, &quot;ham&quot;)
}

# Use the classify function to classify the messages in the training set
final_train &lt;- tidy_train %&gt;% 
  mutate(
    prediction = map_chr(sms, function(m) { classify(m) })
  )</code></pre>
<p>We can now calculate just how accurate our model is at predicting spam and non-spam messages.</p>
<pre class="r"><code># Results of classification on training
confusion &lt;- table(final_train$label, final_train$prediction)
accuracy &lt;- (confusion[1,1] + confusion[2,2]) / nrow(final_train)
accuracy</code></pre>
<pre><code>## [1] 0.9545102</code></pre>
<p>The Naive Bayes Classifier achieves an accuracy of just over 90%. Pretty good! Let’s see how well it works on messages that it has never seen before.</p>
<p>We can attempt to modify the alpha suing the cross-validation dataset to improve the prediction power of our algorithm.</p>
<pre class="r"><code>alpha_grid &lt;- seq(0.05, 1, by = 0.05)
cv_accuracy &lt;- NULL
for (alpha in alpha_grid) {
  
  # Recalculate probabilities based on new alpha
  cv_probs &lt;- word_counts %&gt;% 
    mutate(
      # Calculate the probabilities from the counts based on new alpha
      spam_prob = (spam_count + alpha / (n_spam + alpha * n_vocabulary)),
      ham_prob = (ham_count + alpha) / (n_ham + alpha * n_vocabulary)
    )
  
  # Predict the classification of each message in cross validation
  cv &lt;- spam_cv %&gt;% 
    mutate(
      prediction = map_chr(sms, function(m) { classify(m, alpha = alpha) })
    ) 
  
  # Assess the accuracy of the classifier on cross-validation set
  confusion &lt;- table(cv$label, cv$prediction)
  acc &lt;- (confusion[1,1] + confusion[2,2]) / nrow(cv)
  cv_accuracy &lt;- c(cv_accuracy, acc)
}
# Check out what the best alpha value is
tibble(
  alpha = alpha_grid,
  accuracy = cv_accuracy
)</code></pre>
<pre><code>## # A tibble: 20 x 2
##    alpha accuracy
##    &lt;dbl&gt;    &lt;dbl&gt;
##  1  0.05    0.971
##  2  0.1     0.971
##  3  0.15    0.971
##  4  0.2     0.971
##  5  0.25    0.967
##  6  0.3     0.965
##  7  0.35    0.963
##  8  0.4     0.961
##  9  0.45    0.961
## 10  0.5     0.961
## 11  0.55    0.959
## 12  0.6     0.955
## 13  0.65    0.955
## 14  0.7     0.955
## 15  0.75    0.952
## 16  0.8     0.952
## 17  0.85    0.948
## 18  0.9     0.948
## 19  0.95    0.946
## 20  1       0.944</code></pre>
<p>Judging from the cross-validation set, higher <span class="math inline">\(\alpha\)</span> values cause the accuracy to decrease. We’ll go with <span class="math inline">\(\alpha = 0.1\)</span> since it produces the highest cross-validation prediction accuracy.</p>
<p>Now we can test the performance of the improved algorithim using the test data.</p>
<pre class="r"><code># Reestablishing the proper parameters
optimal_alpha &lt;- 0.1
# Using optimal alpha with training parameters, perform final predictions
spam_test &lt;- spam_test %&gt;% 
  mutate(
    prediction = map_chr(sms, function(m) { classify(m, alpha = optimal_alpha)} )
    )
  
confusion &lt;- table(spam_test$label, spam_test$prediction)
test_accuracy &lt;- (confusion[1,1] + confusion[2,2]) / nrow(spam_test)
test_accuracy</code></pre>
<pre><code>## [1] 0.9793388</code></pre>
<p>We’ve achieved an accuracy of over 96% in the test set.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
